{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ep = 1000\n",
    "steps_per_ep = 200\n",
    "\n",
    "learning_rate = 0.001\n",
    "discount_factor = 0.99\n",
    "exploration_prob = 1.0\n",
    "exploration_decay = 0.995\n",
    "min_exploration_prob = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class DQN(tf.keras.Model):\n",
    "    def __init__(self, n_actions):\n",
    "        super(DQN, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(24, activation='relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(24, activation='relu')\n",
    "        self.output_layer = tf.keras.layers.Dense(\n",
    "            n_actions, activation='linear')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "# POSSIBLE_ACTIONS = [\"0a\", \"0b\", \"1a\", \"1b\", \"2a\", \"2b\", \"2c\", \"2d\"]\n",
    "num_actions = 8\n",
    "dqn_agent = DQN(num_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [], [], []]\n",
      "[]\n",
      "Road 1:  []\n",
      "Road 2:  []\n",
      "Road 3:  []\n",
      "Road 4:  []\n",
      "[[], [], [], []]\n",
      "[]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 20\u001B[0m\n\u001B[0;32m     18\u001B[0m     max_next_q \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mreduce_max(next_q_values, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     19\u001B[0m     target_q_values \u001B[38;5;241m=\u001B[39m current_q_values\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[1;32m---> 20\u001B[0m     \u001B[43mtarget_q_values\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maction\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m reward \u001B[38;5;241m+\u001B[39m discount_factor \u001B[38;5;241m*\u001B[39m max_next_q \u001B[38;5;241m*\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m done)\n\u001B[0;32m     21\u001B[0m     loss \u001B[38;5;241m=\u001B[39m loss_fn(current_q_values, target_q_values)\n\u001B[0;32m     23\u001B[0m gradients \u001B[38;5;241m=\u001B[39m tape\u001B[38;5;241m.\u001B[39mgradient(loss, dqn_agent\u001B[38;5;241m.\u001B[39mtrainable_variables)\n",
      "\u001B[1;31mIndexError\u001B[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "simulator = sim.Sim(steps_per_ep)\n",
    "\n",
    "for episode in range(ep):\n",
    "    state = simulator.reset()\n",
    "    ep_idle = 0\n",
    "\n",
    "    for step in range(steps_per_ep):\n",
    "        if np.random.rand() < exploration_prob:\n",
    "            action = simulator.sample()\n",
    "        else:\n",
    "            # wrong array sizes? - also change input from str to float\n",
    "            action = np.argmax(dqn_agent(state[np.newaxis, :]))\n",
    "\n",
    "        next_state, reward, done = simulator.step(action)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            current_q_values = dqn_agent(state[np.newaxis, :])\n",
    "            next_q_values = dqn_agent(next_state[np.newaxis, :])\n",
    "            max_next_q = tf.reduce_max(next_q_values, axis=-1)\n",
    "            target_q_values = current_q_values.numpy()\n",
    "            target_q_values[0, action] = reward + discount_factor * max_next_q * (1 - done)\n",
    "            loss = loss_fn(current_q_values, target_q_values)\n",
    "\n",
    "        gradients = tape.gradient(loss, dqn_agent.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, dqn_agent.trainable_variables))\n",
    "\n",
    "        state = next_state\n",
    "        ep_idle += reward\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    exploration_prob = max(min_exploration_prob, exploration_prob * exploration_decay)\n",
    "    if (episode + 1)%100==0:\n",
    "        print(f\"Episode {episode + 1}: Reward = {ep_idle}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
